<!DOCTYPE html> <html lang="en"> <head> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5JEZS4MT5D"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5JEZS4MT5D");</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>CharsiuG2P | Dr. Cong Zhang</title> <meta name="author" content="Cong Zhang"/> <meta name="description" content="Grapheme-to-phoneme conversion tool in 100 languages <br><br>" /> <meta name="keywords" content="cong, cong zhang, newcaslte, oxford, linguistics, prosody, phonetics, phonology, speech"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/icon.jpg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://congzhang-linguist.github.io/project/charsiuG2P/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Dr. Cong Zhang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/resources/">resources</a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">awards</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">CharsiuG2P</h1> <p class="post-description">Grapheme-to-phoneme conversion tool in 100 languages <br><br></p> </header> <article> <p>CharsiuG2P is transformer based tool for grapheme-to-phoneme conversion in 100 languages. Given an orthographic word, CharsiuG2P predicts its pronunciation through a neural G2P model.</p> <p>Github repo:</p> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/lingjzhu/CharsiuG2P" target="_blank" rel="noopener noreferrer"> <img class="repo-img-light w-100" alt="lingjzhu/CharsiuG2P" src="https://github-readme-stats.vercel.app/api/pin/?username=lingjzhu&amp;repo=CharsiuG2P&amp;theme=default&amp;show_owner=true"> <img class="repo-img-dark w-100" alt="lingjzhu/CharsiuG2P" src="https://github-readme-stats.vercel.app/api/pin/?username=lingjzhu&amp;repo=CharsiuG2P&amp;theme=dark&amp;show_owner=true"> </a> </div> </div> </article> <h2>Related articles:</h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Interspeech</abbr></div> <div id="zhu2022byt5-g2p" class="col-sm-8"> <div class="title">ByT5 model for massively multilingual grapheme-to-phoneme conversion</div> <div class="author"> Jian Zhu*, Cong Zhang*, and David Jurgens [* equal contribution]</div> <div class="periodical"> <em>In Interspeech 2022</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2204.03067.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/lingjzhu/CharsiuG2P" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>In this study, we tackle massively multilingual grapheme-to-phoneme conversion through implementing G2P models based on ByT5. We have curated a G2P dataset from various sources that covers around 100 languages and trained large-scale multilingual G2P models based on ByT5. We found that ByT5 operating on byte-level inputs significantly outperformed the token-based mT5 model in terms of multilingual G2P. Pairwise comparison with monolingual models in these languages suggests that multilingual ByT5 models generally lower the phone error rate by jointly learning from a variety of languages. The pretrained model can further benefit low resource G2P through zero-shot prediction on unseen languages or provides pretrained weights for finetuning, which helps the model converge to a lower phone error rate than randomly initialized weights. To facilitate future research on multilingual G2P, we make available our code and pretrained multilingual G2P models at: https://github.com/lingjzhu/CharsiuG2P.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhu2022byt5-g2p</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ByT5 model for massively multilingual grapheme-to-phoneme conversion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Jian Zhu*, Cong Zhang*} and {[* equal contribution]}, David Jurgens}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interspeech 2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <ol class="bibliography"></ol> </div> <h2>Related talks:</h2> <div class="publications"> <ol class="bibliography"></ol> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">speech tech</abbr></div> <div id="zhu2022byt5-g2p-c" class="col-sm-8"> <div class="title">ByT5 model for massively multilingual grapheme-to-phoneme conversion</div> <div class="author"> Jian Zhu, <em>Cong Zhang</em>, and David Jurgens</div> <div class="periodical"> <em>Interspeech 2022</em> <br> Incheon, Korea [online], 18-22 sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2204.03067.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/lingjzhu/CharsiuG2P" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>In this study, we tackle massively multilingual grapheme-to-phoneme conversion through implementing G2P models based on ByT5. We have curated a G2P dataset from various sources that covers around 100 languages and trained large-scale multilingual G2P models based on ByT5. We found that ByT5 operating on byte-level inputs significantly outperformed the token-based mT5 model in terms of multilingual G2P. Pairwise comparison with monolingual models in these languages suggests that multilingual ByT5 models generally lower the phone error rate by jointly learning from a variety of languages. The pretrained model can further benefit low resource G2P through zero-shot prediction on unseen languages or provides pretrained weights for finetuning, which helps the model converge to a lower phone error rate than randomly initialized weights. To facilitate future research on multilingual G2P, we make available our code and pretrained multilingual G2P models at: https://github.com/lingjzhu/CharsiuG2P.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">zhu2022byt5-g2p-c</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ByT5 model for massively multilingual grapheme-to-phoneme conversion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Jian and Zhang, Cong and Jurgens, David}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interspeech 2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{18-22 Sep}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Incheon, Korea [online]}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <h2>Related resources:</h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CharsiuG2P</abbr></div> <div id="zhu2022charsiug2p" class="col-sm-8"> <div class="title">CharsiuG2P</div> <div class="author"> Jian Zhu, <em>Cong Zhang</em>, and David Jurgens</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/zhu22_interspeech.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/lingjzhu/charsiuG2P" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>CharsiuG2P is transformer based tool for grapheme-to-phoneme conversion in 100 languages. Given an orthographic word, CharsiuG2P predicts its pronunciation through a neural G2P model. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">zhu2022charsiug2p</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Jian and Zhang, Cong and Jurgens, David}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{CharsiuG2P}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">category</span> <span class="p">=</span> <span class="s">{tool}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">dictionary</abbr></div> <div id="zhu2022charsiug2p-dict" class="col-sm-8"> <div class="title">CharsiuG2P: pronunciation dictionaries</div> <div class="author"> Jian Zhu, <em>Cong Zhang</em>, and David Jurgens</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/lingjzhu/CharsiuG2P/tree/main/dicts" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Data collected for the CharsiuG2P project. This is a collection of pronunciation dictionaries for over 100 languages.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">zhu2022charsiug2p-dict</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Jian and Zhang, Cong and Jurgens, David}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CharsiuG2P: pronunciation dictionaries}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">category</span> <span class="p">=</span> <span class="s">{tool}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">data</abbr></div> <div id="zhu2022charsiug2p-resources" class="col-sm-8"> <div class="title">CharsiuG2P-Data: A Multi-lingual G2P Corpora</div> <div class="author"> Jian Zhu, <em>Cong Zhang</em>, and David Jurgens</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://docs.google.com/spreadsheets/d/1Aq54Un6Q_Dj99_H1Y61iWnTB7xN0xgac5lg4sHU4Gdk/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Data collected for the CharsiuG2P project. This is a collection of pronunciation dictionaries for over 100 languages.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">zhu2022charsiug2p-resources</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Jian and Zhang, Cong and Jurgens, David}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CharsiuG2P-Data: A Multi-lingual G2P Corpora}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">category</span> <span class="p">=</span> <span class="s">{tool}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Cong Zhang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5JEZS4MT5D"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5JEZS4MT5D");</script> </body> </html>